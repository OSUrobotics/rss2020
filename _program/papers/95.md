---
layout: paper
title: "Robust Multiple-Path Orienteering Problem: Securing Against Adversarial Attacks"
invisible: true
---
*[Pratap Tokekar](http://tokekar.com/), [Lifeng Zhou](https://lfzhou917.github.io/)*
{: style="color:black; font-size: 120%; text-align: center;"}

### Abstract
<html><p style="color:gray; font-size: 120%; text-align: justified;">
The multiple-path orienteering problem asks for
paths for a team of robots that maximize the total reward
collected while satisfying budget constraints on the path length.
This problem models many multi-robot routing tasks such as
exploring unknown environments and information gathering for
environmental monitoring. In this paper, we focus on how to
make the robot team robust to failures when operating in
adversarial environments. We introduce the Robust Multiple path
Orienteering Problem (RMOP) where we seek worst-case
guarantees against an adversary that is capable of attacking at
most \alpha robots. Our main contribution is a general approximation
scheme with bounded approximation guarantee that depends on
\alpha and the approximation factor for single robot orienteering.
In particular, we show that the algorithm yields a (i) constant factor
approximation when the cost function is modular; (ii)
log factor approximation when the cost function is submodular;
and (iii) constant-factor approximation when the cost function
is submodular but the robots are allowed to exceed their path
budgets by a bounded amount. In addition to theoretical analysis,
we perform simulation study for an ocean monitoring application
to demonstrate the efficacy of our approach.
</p></html>



