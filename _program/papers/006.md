---
layout: paper
title: "Policy Transfer across Visual and Dynamics Domain Gaps via Iterative Grounding"
invisible: true
---
<table width = "95%" style="padding-left: 15px; margin-left: auto; margin-right: 10px;">
<tr><td style = "vertical-align: top; padding-right: 25px;" rowspan="2">
<span style="color:black; font-size: 110%;"><i>
Grace Zhang <span style="color:gray; font-size: 85%">(University of Southern California)</span><span style="color:gray; font-size: 100%">,</span><br>  Linghan Zhong <span style="color:gray; font-size: 85%">(University of Southern California)</span><span style="color:gray; font-size: 100%">,</span><br>  Youngwoon Lee <span style="color:gray; font-size: 85%">(University of Southern California)</span><span style="color:gray; font-size: 100%">,</span><br>  Joseph J Lim <span style="color:gray; font-size: 85%">(University of Southern California)</span>
</i></span>
</td>
<td style="text-align: right;"><a href="http://www.roboticsproceedings.org/rss17/p006.pdf"><img src="{{ site.baseurl }}/images/paper_link.png" alt="Paper Website" width = "50"  height = "60"/></a><br> <a href="https://clvrai.com/idapt"><img src="{{ site.baseurl }}/images/website_link.png" alt="Paper Website" width = "50"  height = "60"/></a><br>    </td>
</tr>
<tr>
<td style="color:#777789; text-align:right; font-size: 75%; margin-right:10px;">Paper&nbsp;#006</td>
</tr>
</table>


### Abstract
The ability to transfer a policy from one environment to another is a promising avenue for efficient robot learning in realistic settings where task supervision is not available. This can allow us to take advantage of environments well suited for training; such as simulators or laboratories; to learn a policy for a real robot in a home or office. To succeed; such policy transfer must overcome both the visual domain gap (e.g. different illumination or background) and the dynamics domain gap (e.g. different robot calibration or modelling error) between source and target environments. However; prior policy transfer approaches either cannot handle a large domain gap or can only address one type of domain gap at a time. In this paper; we propose a novel policy transfer method with iterative "environment grounding"; IDAPT; that alternates between (1) directly minimizing both visual and dynamics domain gaps by grounding the source environment in the target environment domains; and (2) training a policy on the grounded source environment. This iterative training progressively aligns the domains between the two environments and adapts the policy to the target environment. Once trained; the policy can be directly executed on the target environment. The empirical results on locomotion and robotic manipulation tasks demonstrate that our approach can effectively transfer a policy across visual and dynamics domain gaps with minimal supervision and interaction with the target environment. Videos and code are available at <a href="https://clvrai.com/idapt">https://clvrai.com/idapt</a>
{: style="color:gray; font-size: 120%; text-align: justified;"}



<table width="100%">
 <tr>
    <td style="width: 30%; text-align: center;"><a href="{{ site.baseurl }}/program/papers/005/">
<img src="{{ site.baseurl }}/images/previous_icon.png"
       alt="Previous Paper" width = "142"  height = "90"/> 
</a> </td>
<td style="text-align: center;"><a href="{{ site.baseurl }}/program/papers">
<img src="{{ site.baseurl }}/images/overview_icon.png"
       alt="Paper Website" width = "142"  height = "90"/> 
</a> </td>
    <td style="width: 30%; text-align: center;"><a href="{{ site.baseurl }}/program/papers/007/">
    <img src="{{ site.baseurl }}/images/next_icon.png"
        alt="Next Paper" width = "142"  height = "90"/>
    </a></td>
</tr>
</table>