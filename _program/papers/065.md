---
layout: paper
title: "Error-Aware Policy Learning: Zero-Shot Generalization in Partially Observable Dynamic Environments"
invisible: true
---
<table width = "95%" style="padding-left: 15px; margin-left: auto; margin-right: 10px;">
<tr><td style = "vertical-align: top; padding-right: 25px;" rowspan="2">
<span style="color:black; font-size: 110%;"><i>
Visak C V Kumar <span style="color:gray; font-size: 85%">(Georgia Tech)</span><span style="color:gray; font-size: 100%">,</span><br>  Sehoon Ha <span style="color:gray; font-size: 85%">(Georgia Tech)</span><span style="color:gray; font-size: 100%">,</span><br>  C. Karen  Liu <span style="color:gray; font-size: 85%">(Stanford University)</span>
</i></span>
</td>
<td style="text-align: right;"><a href="http://www.roboticsproceedings.org/rss17/p065.pdf"><img src="{{ site.baseurl }}/images/paper_link.png" alt="Paper Website" width = "50"  height = "60"/></a><br>     </td>
</tr>
<tr>
<td style="color:#777789; text-align:right; font-size: 75%; margin-right:10px;">Paper&nbsp;#065</td>
</tr>
</table>


### Abstract
Simulation provides a safe and efficient way to generate useful data for learning complex robotic tasks. However, matching simulation and real-world dynamics can be quite challenging, especially for systems that have a large number of unobserved or unmeasurable parameters, which may lie in the robot dynamics itself or in the environment with which the robot interacts. We introduce a novel approach to tackle such a sim-to-real problem by developing policies capable of adapting to new environments, in a zero-shot manner. Key to our approach is an error-aware policy (EAP) that is explicitly made aware of the effect of unobservable factors during training. An EAP takes as input the predicted future state error in the target environment, which is provided by an error-prediction function, simultaneously trained with the EAP. We validate our approach on an assistive walking device trained to help the human user recover from external pushes. We show that a trained EAP for a hip-torque assistive device can be transferred to different human agents with unseen biomechanical characteristics. In addition, we show that our method can be applied to other standard RL control tasks.
{: style="color:gray; font-size: 120%; text-align: justified;"}



<table width="100%">
 <tr>
    <td style="width: 30%; text-align: center;"><a href="{{ site.baseurl }}/program/papers/064/">
<img src="{{ site.baseurl }}/images/previous_icon.png"
       alt="Previous Paper" width = "142"  height = "90"/> 
</a> </td>
<td style="text-align: center;"><a href="{{ site.baseurl }}/program/papers">
<img src="{{ site.baseurl }}/images/overview_icon.png"
       alt="Paper Website" width = "142"  height = "90"/> 
</a> </td>
    <td style="width: 30%; text-align: center;"><a href="{{ site.baseurl }}/program/papers/066/">
    <img src="{{ site.baseurl }}/images/next_icon.png"
        alt="Next Paper" width = "142"  height = "90"/>
    </a></td>
</tr>
</table>