---
layout: paper
title: "Active Learning of Abstract Plan Feasibility"
invisible: true
---
<table width = "95%" style="padding-left: 15px; margin-left: auto; margin-right: 10px;">
<tr><td style = "vertical-align: top; padding-right: 25px;" rowspan="2">
<span style="color:black; font-size: 110%;"><i>
Michael Noseworthy <span style="color:gray; font-size: 85%">(MIT)</span><span style="color:gray; font-size: 100%">,</span><br>  Isaiah Brand <span style="color:gray; font-size: 85%">(MIT)</span><span style="color:gray; font-size: 100%">,</span><br>  Caris Moses <span style="color:gray; font-size: 85%">(MIT)</span><span style="color:gray; font-size: 100%">,</span><br>  Sebastian Castro <span style="color:gray; font-size: 85%">(MIT)</span><span style="color:gray; font-size: 100%">,</span><br>  Leslie Kaelbling <span style="color:gray; font-size: 85%">(MIT)</span><span style="color:gray; font-size: 100%">,</span><br>  Tomas Lozano-Perez <span style="color:gray; font-size: 85%">(MIT)</span><span style="color:gray; font-size: 100%">,</span><br>  Nicholas Roy <span style="color:gray; font-size: 85%">(MIT)</span>
</i></span>
</td>
<td style="text-align: right;"><a href="http://www.roboticsproceedings.org/rss17/p043.pdf"><img src="{{ site.baseurl }}/images/paper_link.png" alt="Paper Website" width = "50"  height = "60"/></a><br>  <a href="https://youtu.be/UF-SjGm20Mw"><img src="{{ site.baseurl }}/images/video_link.png" alt="Code" width = "50"  height = "60"/></a><br>   </td>
</tr>
<tr>
<td style="color:#777789; text-align:right; font-size: 75%; margin-right:10px;">Paper&nbsp;#043</td>
</tr>
</table>


### Abstract
Long horizon sequential manipulation tasks are effectively addressed hierarchically: at a high level of abstraction the planner searches over abstract action sequences; and when a plan is found; lower level motion plans are generated. Such a strategy hinges on the ability to reliably predict that a feasible low level plan will be found which satisfies the abstract plan. However; computing Abstract Plan Feasibility (APF) is difficult because the outcome of a plan depends on complex real-world phenomena that are computationally costly to model; such as noise in estimation and plan execution.  In this work; we present an active learning approach to efficiently acquire an APF predictor through curious exploration on a robot. The robot identifies plans whose outcomes would be informative about APF; executes those plans; and learns from their subsequent successes or failures. We evaluate our strategy in simulation and on a real Franka Emika Panda robot with integrated perception; experimentation; planning; and execution. In a stacking domain where objects have non-uniform mass distributions; we show that our system permits real-robot learning of an APF model in four hundred self-supervised interactions; and that our learned model can be used effectively in different downstream tasks (e.g.; constructing the tallest tower or tower with the longest overhang).
{: style="color:gray; font-size: 120%; text-align: justified;"}



<table width="100%">
 <tr>
    <td style="width: 30%; text-align: center;"><a href="{{ site.baseurl }}/program/papers/042/">
<img src="{{ site.baseurl }}/images/previous_icon.png"
       alt="Previous Paper" width = "142"  height = "90"/> 
</a> </td>
<td style="text-align: center;"><a href="{{ site.baseurl }}/program/papers">
<img src="{{ site.baseurl }}/images/overview_icon.png"
       alt="Paper Website" width = "142"  height = "90"/> 
</a> </td>
    <td style="width: 30%; text-align: center;"><a href="{{ site.baseurl }}/program/papers/044/">
    <img src="{{ site.baseurl }}/images/next_icon.png"
        alt="Next Paper" width = "142"  height = "90"/>
    </a></td>
</tr>
</table>