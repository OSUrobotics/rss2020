---
layout: paper
title: "Manipulator-Independent Representations for Visual Imitation"
invisible: true
---
<head>
<style>
* {
  box-sizing: border-box;
}

#myInput {
  background-position: 10px 10px;
  background-repeat: no-repeat;
  width: 100%;
  font-size: 100%;
  padding: 12px 20px 12px 40px;
  border: 1px solid #ddd;
  margin-bottom: 12px;
}

#myTable {
  border-collapse: collapse;
  width: 100%;
  border: 1px solid #ddd;
  font-size: 100%;
}

#myTable th, #myTable td {
  text-align: left;
  padding: 12px;
}

#myTable tr {
  border-bottom: 1px solid #ddd;
}

#myTable tr.header, #myTable tr:hover {
  background-color: #f1f1f1;
}

#eventcounter1 a {
    font-size: 12px;
    color: #ffffff;
    display: block;
}

#eventcounter1 a:hover {
    text-decoration: none;
}

#eventcounter2 a {
    font-size: 12px;
    color: #ffffff;
    display: block;
}

#eventcounter2 a:hover {
    text-decoration: none;
}

</style>
</head>

<table width = "95%" style="padding-left: 15px; margin-left: auto; margin-right: 10px;">
<tr><td style = "vertical-align: top; padding-right: 25px;" rowspan="2">
<span style="color:black; font-size: 110%;"><i>
Yuxiang Zhou <span style="color:gray; font-size: 85%">(DeepMind)</span><span style="color:gray; font-size: 100%">,</span><br>  Yusuf Aytar <span style="color:gray; font-size: 85%">(DeepMind)</span><span style="color:gray; font-size: 100%">,</span><br>  Konstantinos Bousmalis <span style="color:gray; font-size: 85%">(DeepMind)</span>
</i></span>
</td>
<td style="text-align: right;"><a href="http://www.roboticsproceedings.org/rss17/p002.pdf"><img src="{{ site.baseurl }}/images/paper_link.png" alt="Paper Website" width = "33"  height = "40"/></a><br> <a href="https://sites.google.com/view/mir4vi"><img src="{{ site.baseurl }}/images/website_link.png" alt="Paper Website" width = "33"  height = "40"/></a><br>    </td>
</tr>
<tr>
<td style="color:#777789; text-align:right; font-size: 75%; margin-right:10px;">Paper&nbsp;#002</td>
</tr>
</table>

<table width="80%" style="margin-top: 20px; margin-left: auto; margin-right: auto;">
                                          <tr><td style="text-align:center;"><a href="{{ site.baseurl }}/program/posters5/">Interactive Poster Session V</a></td> 
                                              <td style="text-align:center;"><a href="{{ site.baseurl }}/program/posters8/">Interactive Poster Session VIII</a></td></tr>
<tr><td><p style="text-align: center; font-size: 10px; margin-top: 0px;" id="eventcounter1"><a>0d 00h 00m</a></p></td><td><p style="text-align: center; font-size: 10px; margin-top: 0px;" id="eventcounter2"><a>0d 00h 00m</a></p></td></tr></table>
<br>


### Abstract
Imitation learning is an effective tool for robotic learning tasks where specifying a reinforcement learning (RL) reward is not feasible or where the exploration problem is particularly difficult. Imitation, typically behavior cloning or inverse RL, derive a policy from a collection of first-person action-state trajectories. This is contrary to how humans and other animals imitate: we observe a behavior, even from other species, understand its perceived effect on the state of the environment, and figure out what actions our body can perform to reach a similar outcome. In this work, we explore the possibility of third-person visual imitation of manipulation trajectories, only from vision and without access to actions, demonstrated by embodiments different to the ones of our imitating agent. Specifically, we investigate what would be an appropriate representation method with which an RL agent can visually track trajectories of complex manipulation behavior &mdash;non-planar with multiple-object interactions&mdash; demonstrated by experts with different embodiments. We present a way to train manipulator-independent representations (MIR) that primarily focus on the change in the environment and have all the characteristics that make them suitable for cross-embodiment visual imitation with RL: domain-invariant, temporally smooth, and actionable. We show that with our proposed method our agents are able to imitate, with complex robot control, trajectories from a variety of embodiments and with significant visual and dynamics differences, e.g. simulation-to-reality gap.
{: style="color:gray; font-size: 120%; text-align: justified;"}




### Spotlight Presentation
<center><span style="font-size:smaller;"><i>This video will be released on July 13th.</i></span></center><br>
<iframe width="100%" height="400" src="https://www.youtube.com/embed/PdU_ZC6Jvck" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

### Links
* [Project page](https://sites.google.com/view/mir4vi)


<table width="100%" style="margin-top:40px;">
 <tr>
    <td style="width: 30%; text-align: center;"><a href="{{ site.baseurl }}/program/papers/001/">
<img src="{{ site.baseurl }}/images/previous_paper_icon.png"
       alt="Previous Paper" width = "142"  height = "90"/> 
</a> </td>
<td style="text-align: center;"><a href="{{ site.baseurl }}/program/papers">
<img src="{{ site.baseurl }}/images/overview_icon.png"
       alt="Paper Website" width = "142"  height = "90"/> 
</a> </td>
    <td style="width: 30%; text-align: center;"><a href="{{ site.baseurl }}/program/papers/003/">
    <img src="{{ site.baseurl }}/images/next_paper_icon.png"
        alt="Next Paper" width = "142"  height = "90"/>
    </a></td>
</tr>
</table>


<script>
var startDate1 = new Date("2021-07-14 08:15:00 UTC-0700").getTime();
var finDate1 = new Date("2021-07-14 09:30:00 UTC-0700").getTime();

// Update the count down every 1 second
var x1 = function() {

  // Get today's date and time
  var now1 = new Date().getTime();
    
  var distToStart1 = startDate1 - now1;
  if (distToStart1 > 0) {

      var days = Math.floor(distToStart1 / (1000 * 60 * 60 * 24));
      var hours = Math.floor((distToStart1 % (1000 * 60 * 60 * 24)) / (1000 * 60 * 60));
      var minutes = Math.floor((distToStart1 % (1000 * 60 * 60)) / (1000 * 60));
   
      document.getElementById("eventcounter1").innerHTML = "<a><span style='color: #aaaaaa;'>" + days + "d " + hours + "h " + minutes + "m</span></a>" ;
      setTimeout(x1, 5000); 
    
  } else {

        var distToEnd1 = finDate1 - now1;

        if (distToEnd1 > 0) {
            document.getElementById("eventcounter1").innerHTML = '<img src="{{ site.baseurl }}/images/live-icon-small.gif" alt="Event is Live" width="64" height=17"><a><span style="color: #ffaaaa;">'+ distToEnd1 +'</span></a> ';
            setTimeout(x1, 30000); 
        }
        else
        { 
            document.getElementById("eventcounter1").innerHTML = "<a><span style='color: #aaaaaa;'>Now concluded</span></a>";
        }
  }
};

setTimeout(x1,0);
</script>

    
<script>
var startDate2 = new Date("2021-07-16 08:15:00 UTC-0700").getTime();
var finDate2 = new Date("2021-07-15 09:30:00 UTC-0700").getTime();

// Update the count down every 1 second
var x2 = function() {

  // Get today's date and time
  var now2 = new Date().getTime();
    
  var distToStart2 = startDate2 - now2;
  if (distToStart2 > 0) {

      var days = Math.floor(distToStart2 / (1000 * 60 * 60 * 24));
      var hours = Math.floor((distToStart2 % (1000 * 60 * 60 * 24)) / (1000 * 60 * 60));
      var minutes = Math.floor((distToStart2 % (1000 * 60 * 60)) / (1000 * 60));
   
      document.getElementById("eventcounter2").innerHTML = "<a><span style='color: #aaaaaa;'>" + days + "d " + hours + "h " + minutes + "m</span></a>" ;
      setTimeout(x2, 5000); 
    
  } else {

        var distToEnd2 = finDate2 - now2;

        if (distToEnd2 > 0) {
            document.getElementById("eventcounter2").innerHTML = '<img src="{{ site.baseurl }}/images/live-icon-small.gif" alt="Event is Live" width="64" height=17"><a><span style="color: #ffaaaa;">'+ distToEnd2 +'</span></a> ';
            setTimeout(x2, 30000); 
        }
        else
        { 
            document.getElementById("eventcounter2").innerHTML = "<a><span style='color: #aaaaaa;'>Now concluded</span></a>";
        }
  }
};

setTimeout(x2,0);
</script>

    