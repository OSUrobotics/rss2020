---
layout: paper
title: "Towards Embodied Scene Description"
invisible: true
---
*[Huaping Liu](https://sites.google.com/site/thuliuhuaping)*
{: style="color:black; font-size: 120%; text-align: center;"}

### Abstract
<html><p style="color:gray; font-size: 120%; text-align: justified;">
Embodiment is an important characteristic for all intelligent agents (creatures and robots), while existing scene description tasks mainly focus on analyzing images passively and the semantic understanding of the scenario is separated from the interaction between the agent and the environment. In this work, we propose the \textit{Embodied Scene Description}, which exploits the embodiment ability of the agent to find an optimal viewpoint in its environment for scene description tasks. A learning framework with the paradigms of imitation learning and reinforcement learning is established to teach the intelligent agent to generate corresponding sensorimotor activities. The proposed framework is tested on both the AI2Thor dataset and a real world robotic platform demonstrating the effectiveness and extendability of the developed method.
</p></html>

### Supplementary Video
<iframe width="560" height="315" src="https://www.youtube.com/embed/KEeUmyhOL2o " frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>



