"""
Script for cleaning paper CSV file.
Script for generating individual paper pages.

NOTE: raw_papers.txt must be generated by exporting from Excel in "UTF-16 Unicode Text (.txt)".
This resolves an assortment of encoding issues for Latin-1 characters.

python3 _data/scripts/papers.py raw_papers.txt _papers _data/papers.csv _program/papers
"""

import argparse
import codecs
import csv
import os
import shutil

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('tsv_infile', help='Excel-exported paper data')
    parser.add_argument('pdfdir', help='Directory of camera-ready PDFs')
    parser.add_argument('csv_outfile', help='Path to CSV file')
    parser.add_argument('outdir', help='Directory for all output files')
    args = parser.parse_args()

    os.makedirs(args.outdir, exist_ok=True)

    # Read raw paper information
    with codecs.open(args.tsv_infile, 'r', 'utf16') as f:
        reader = csv.DictReader(f, delimiter='\t')
        raw_paper_data = sorted(reader,
            key=lambda d: d['Paper Title'].replace('(', '').lower())

    # Generate paper CSV and pages
    with open(args.csv_outfile, 'w') as f:
        writer = csv.DictWriter(f, fieldnames=[
            'session_id', 'external_id', 'internal_id',
            'title', 'abstract', 'authors', 'areas'])

        writer.writeheader()
        for i, raw_paper in enumerate(raw_paper_data, 1):
            abstract = raw_paper['Abstract'].encode('ascii', 'xmlcharrefreplace').decode()
            authors = ', '.join([
                ' '.join(author.split(',')[0].replace('*', '').split())
                for author in raw_paper['Author Names'].encode('ascii', 'xmlcharrefreplace').decode().split('; ')
            ])

            paper = {
                'session_id': 0,
                'external_id': '{:0>2}'.format(i),
                'internal_id': raw_paper['Paper ID'],
                'title': raw_paper['Paper Title'],
                'abstract': abstract,
                'authors': authors,
                'areas': raw_paper['Subject Areas'],
            }

            # Write row to CSV
            writer.writerow(paper)

            front_matter = [
                '-' * 3,
                'layout: paper',
                'title: "{}"'.format(paper['title']),
                'comments: true',
                'invisible: true',
                '-' * 3,
            ]
            data = [
                'Authors: {authors}'.format(authors=paper['authors']),
                'Link: <a href="https://storage.googleapis.com/rss2017-papers/{external_id:0>2}.pdf">{external_id:0>2}.pdf</a>'.format(external_id=i),
            ]
            formatted_data = ['<p class="text-left"><i>{}</i></p>'.format(d) for d in data]

            # Generate page
            outpath = os.path.join(args.outdir,  '{id}.md'.format(id=paper['external_id']))
            with open(outpath, 'w') as fout:
                page_data = [
                    '\n'.join(front_matter),
                    '\n'.join(formatted_data),
                    paper['abstract'],
                    '{% include disqus.html %}'
                ]
                fout.write('\n\n'.join(page_data))

            pdf_inpath = os.path.join(args.pdfdir,
                                      'Paper {internal_id}.pdf'.format(
                                          internal_id=raw_paper['Paper ID']))
            pdf_outpath = os.path.join(args.outdir,
                                       '{external_id:0>2}.pdf'.format(external_id=i))
            shutil.copyfile(pdf_inpath, pdf_outpath)

if __name__ == '__main__':
    main()    
